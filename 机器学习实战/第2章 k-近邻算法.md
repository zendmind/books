# 第二章 $K$-近邻算法

## 2.1 $K$-近邻算法概述

$k$-近邻算法采用不同特征值之间的距离方法进行分类
- 优点：精度高，对异常值不敏感，无数据输入假定  
- 缺点：计算复杂度高，空间复杂度高  
- 适用数据范围：数值型和标称型  

工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前$k$个最相似的数据，这就是$k$-近邻算法中$k$的出处，通常$k$是不大于20的整数。最后，选择$k$个最近似数据中出现次数最多的分类，作为新数据的分类。  

$k$-近邻算法的一般流程
1. 收集数据：可以使用任何方法
2. 准备数据：距离计算所需要的数值，最好是结构化的数据格式
3. 分析数据：可以使用任何方法
4. 训练算法：此步骤不适用于k-近邻算法
5. 测试算法：计算错误率
6. 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行$k$-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理  

### 2.1.1 使用Python导入数据

```
from numpy import *
import operator

def createDataSet ():
  group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])
  labels = ['A', 'A', 'B', 'B']
  return group, labels
```

### 2.1.2 从文本文件中解析数据

伪代码如下：
> 对未知类别属性的数据集中的每个点依次执行以下操作：
> （1）计算已知类别数据集中的点与当前点之间的距离
> （2）按照距离递增依次排序
> （3）选取与当前点距离最小的k个点
> （4）确定前k个点所在类别的出现频率
> （5）返回前k个点出现频率最高的类别作为当前点的预测分类

```
from numpy import *
import operator

def createDataSet ():
  group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])
  labels = ['A', 'A', 'B', 'B']
  return group, labels

def classify0 (inX, dataSet, labels, k):
  dataSetSize = dataSet.shape[0]
  diffMat = tile(inX, (dataSetSize, 1)) - dataSet
  sqDiffMat = diffMat**2
  sqDistances = sqDiffMat.sum(axis=1)
  distances = sqDistances**0.5
  sortedDistatIndicies = distances.argsort()
  classCount={}
  for i in range (k):
      voteIlabel = labels[sortedDistatIndicies[i]]
      classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1
  sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
  return sortedClassCount[0][0]

group, labels = createDataSet()
```

为了测试分类器的效果，可以使用已知答案的数据，通过大量的测试数据，可以得到分类器的错误率--分类器给出错误结果的次数除以测试执行的总数。

## 2.2 示例：使用$k$-近邻算法改进约会网站的配对效果

伪代码如下：
> 1. 收集数据：提供文本文件
> 2. 准备数据：使用python解析文本文件
> 3. 分析数据：使用Matplotlib画二维扩散图
> 4. 训练算法：此步骤不适用于$k$-近邻算法
> 5. 测试算法：使用海伦提供的部分数据做为测试样本（测试样本和非测试样本的区别在于：测试样本是已经完成分类的数据，如果预测分类于实际类别不同，则标记为一个错误）
> 6. 使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型

### 2.2.1 准备数据：从文本文件中解析数据

```
def file2matrix(filename):
  fr = open(filename)
  arrayOLines = fr.readlines()
  numberOfLines = len(arrayOLines)
  returnMat = zeros((numberOfLines, 3))
  classLabelVector = []
  index = 0
  for line in arrayOLines:
    line = line.strip()
    listFromLine = line.split('\t')
    returnMat[index, :] = listFromLine[0:3]
    classLabelVector.append(int(listFromLine[-1]))
    index += 1
  return  
```

### 2.2.2 分析数据：使用Matplotlib创建散点图

```
# -*- coding: UTF-8 -*-

from numpy import *
import matplotlib
import matplotlib.pyplot as pyplot
import kNN

fig = pyplot.figure()
ax = fig.add_subplot(111)
datingDataMat,datingLabels = kNN.file2matrix('/Users/fengxing/Documents/workspace/wangxutech/git/books/机器学习实战/source code/Ch02/datingTestSet2.txt')
ax.scatter(datingDataMat[:,1], datingDataMat[:,2], 15.0*array(datingLabels), 15.0*array(datingLabels))
ax.axis([-2,25,-0.2,2.0])
pyplot.xlabel('Percentage of Time Spent Playing Video Games')
pyplot.ylabel('Liters of Ice Cream Consumed Per Week')
pyplot.show()
```

### 2.2.3 准备数据：归一化数值

在处理不同取值范围的特征值时，通常采用的方法是将数值归一化，如将取值范围处理为0到1或者-1到1之间:
```
newValue = (oldValue - min) / (max - min)
```
